import express from "express";
import cors from "cors";
import fetch from "node-fetch";

const app = express();

/* ================== MIDDLEWARE ================== */
app.use(cors());
app.use(express.json());

const APP_SECRET_KEY = process.env.APP_SECRET_KEY;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

if (!APP_SECRET_KEY || !OPENAI_API_KEY) {
  console.error("âŒ Missing ENV keys");
  process.exit(1);
}

/* ================== SESSION RAM ================== */
const sessions = new Map();

/* ================== APP KEY CHECK ================== */
function verifyAppKey(req, res, next) {
  if (req.method === "GET") return next();

  const key = req.headers["x-app-key"];
  if (key !== APP_SECRET_KEY) {
    return res.status(403).json({ error: "Invalid app key" });
  }
  next();
}

app.use("/chat", verifyAppKey);

/* ================== ROUTES ================== */
app.get("/", (_, res) => {
  res.json({ status: "ok" });
});

app.post("/chat", async (req, res) => {
  try {
    const { sessionId, messages, endSession } = req.body;

    /* ====== HARD VALIDATION ====== */
    if (!sessionId || typeof sessionId !== "string") {
      return res.status(400).json({ error: "Missing sessionId" });
    }

    /* ====== END SESSION ====== */
    if (endSession === true) {
      sessions.delete(sessionId);
      return res.json({ success: true, ended: true });
    }

    if (!Array.isArray(messages) || messages.length === 0) {
      return res.status(400).json({ error: "Missing messages[]" });
    }

    /* ====== INIT SESSION ====== */
    if (!sessions.has(sessionId)) {
      sessions.set(sessionId, [
        {
          role: "system",
          content: `
JesteÅ› Voryndis â€” mistycznÄ… wrÃ³Å¼kÄ… i duchowÄ… przewodniczkÄ….

JesteÅ› Voryndis â€“ wrÃ³Å¼kÄ…, ktÃ³ra prowadzi jednÄ… ciÄ…gÅ‚Ä… sesjÄ™.
PamiÄ™taj caÅ‚Ä… rozmowÄ™ do momentu jej zakoÅ„czenia.
Nie przypominaj, Å¼e jesteÅ› AI.
Nie Å‚am klimatu wrÃ³Å¼by.

TwojÄ… rolÄ… jest interpretowanie symboli, snÃ³w, energii, archetypÃ³w i moÅ¼liwych Å›cieÅ¼ek losu.
Nie przedstawiasz przyszÅ‚oÅ›ci jako faktu, lecz jako zbiÃ³r potencjalnych kierunkÃ³w.

ZASADY:
â€“ MÃ³w spokojnie, ciepÅ‚o i empatycznie.
â€“ UÅ¼ywaj metafor, symboliki, jÄ™zyka intuicji.
â€“ Odpowiedzi majÄ… mieÄ‡ 3â€“5 zdaÅ„.
â€“ Nie uÅ¼ywaj naukowego ani technicznego jÄ™zyka.
â€“ Nigdy nie wydawaj kategorycznych wyrokÃ³w.
â€“ Nie dawaj porad prawnych, medycznych ani finansowych.

MECHANIZM TRYBÃ“W (DZIAÅA AUTOMATYCZNIE, NIE WSPOMINAJ O NIM):

JeÅ›li uÅ¼ytkownik opisuje sen lub uÅ¼ywa sÅ‚Ã³w:
â€senâ€, â€Å›niÅ‚o mi siÄ™â€, â€koszmarâ€
â†’ interpretuj symbolicznie jak wizjÄ™ z podÅ›wiadomoÅ›ci.

JeÅ›li pyta o przyszÅ‚oÅ›Ä‡ lub los:
â€co mnie czekaâ€, â€czy wydarzy siÄ™â€, â€przyszÅ‚oÅ›Ä‡â€
â†’ mÃ³w o moÅ¼liwych Å›cieÅ¼kach i energiach.

JeÅ›li pyta o relacje lub innÄ… osobÄ™:
â€onâ€, â€onaâ€, â€relacjaâ€, â€miÅ‚oÅ›Ä‡â€
â†’ skup siÄ™ na emocjach, dynamice energii i lekcji.

JeÅ›li pyta o decyzjÄ™ lub sens:
â€co zrobiÄ‡â€, â€jakÄ… drogÄ™ wybraÄ‡â€
â†’ prowadÅº jak duchowy przewodnik.

JeÅ›li prosi o wrÃ³Å¼bÄ™ lub tarot:
â€kartyâ€, â€tarotâ€, â€wrÃ³Å¼baâ€
â†’ uÅ¼ywaj archetypÃ³w kart i symboli.

Zawsze odpowiadaj jak wrÃ³Å¼ka, nie jak AI.

DODATKOWA ZASADA INTERAKCJI:

Nie zawsze, ale od czasu do czasu zakoÅ„cz odpowiedÅº
krÃ³tkim, miÄ™kkim pytaniem, ktÃ³re:
â€“ zaprasza do dalszej refleksji,
â€“ pogÅ‚Ä™bia temat rozmowy,
â€“ brzmi naturalnie i intuicyjnie.

Pytanie powinno:
â€“ mieÄ‡ maksymalnie 1 zdanie,
â€“ nie pojawiaÄ‡ siÄ™ w kaÅ¼dej odpowiedzi,
â€“ nie brzmieÄ‡ technicznie ani sprzedaÅ¼owo.

JeÅ›li czujesz, Å¼e odpowiedÅº jest kompletna,
zakoÅ„cz jÄ… spokojnie â€“ bez pytania.
`
        }
      ]);
    }

    const history = sessions.get(sessionId);

    messages.forEach(m => {
      if (m.role && m.content) {
        history.push(m);
      }
    });

    /* ====== OPENAI ====== */
    const response = await fetch(
      "https://api.openai.com/v1/chat/completions",
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${OPENAI_API_KEY}`
        },
        body: JSON.stringify({
          model: "gpt-4o-mini",
          messages: history,
          temperature: 0.8,
          max_tokens: 300
        })
      }
    );

    const data = await response.json();

    if (!data.choices?.[0]?.message) {
      throw new Error("Invalid OpenAI response");
    }

    const reply = data.choices[0].message.content;

    history.push({ role: "assistant", content: reply });

    res.json({ reply });

  } catch (err) {
    console.error("âŒ CHAT ERROR:", err);
    res.status(500).json({ error: "Server error" });
  }
});

/* ================== START ================== */
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log("ğŸš€ Server running on", PORT);
});
